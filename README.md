# ğŸš€ âš¡ The Power of LLMs: Keyword Extraction from Any Webpage (Even JS-Powered Ones!)

A full-stack AI project that extracts meaningful keywords from **any webpage**, including JavaScript-heavy sites, using **Playwright**, **LLMs**, and **Vector DBs**. Built with **FastAPI**, **Streamlit**, and **Docker**, and production-ready with **CI/CD**.

---

## ğŸ” Features

- âœ… Scrapes both static and JavaScript-enabled pages using Playwright  
- âœ… Supports 4 extraction methods: `LLM`, `RAKE`, `TF-IDF`, `KeyBERT`  
- âœ… Uses SentenceTransformers for vector embeddings  
- âœ… Stores embeddings in FAISS for semantic search  
- âœ… Outputs are JSON-compatible (MongoDB-ready)  
- âœ… Fully interactive UI built with Streamlit  
- âœ… Dockerized and ready to deploy  
- âœ… GitHub Actions CI/CD pipeline included  

---

## ğŸ§  System Architecture

```text
Webpage (HTML or JS)
        â†“
Playwright (Headless Browser Scraper)
        â†“
Keyword Extraction (RAKE | TF-IDF | KeyBERT | LLM)
        â†“
      â”Œâ”€â”€â”€â”€â”€â–º FAISS Vector Store (for semantic search)
      â”‚
      â””â”€â”€â”€â”€â”€â–º JSON Output (MongoDB-ready)
        â†“
Streamlit UI (Visualization & Querying)
```

---

## ğŸ“ Project Structure

```text
.
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ main.py
â”‚   â”œâ”€â”€ scraper.py
â”‚   â”œâ”€â”€ processor.py
â”‚   â”œâ”€â”€ vectorstore.py
â”‚   â””â”€â”€ requirements.txt
â”œâ”€â”€ ui/
â”‚   â””â”€â”€ app.py
â”œâ”€â”€ diagram/
â”‚   â”œâ”€â”€ Structure.png
â”‚   â””â”€â”€ Frontend.png
â”œâ”€â”€ Dockerfile.backend
â”œâ”€â”€ Dockerfile.frontend
â”œâ”€â”€ docker-compose.yaml
â””â”€â”€ .github/
    â””â”€â”€ workflows/
        â””â”€â”€ ci.yml
```

---

## ğŸ–¼ï¸ Visuals

### ğŸ”§ System Diagram

![Structure](diagram/Structure.png)

### ğŸ¨ Frontend Screenshot

![Frontend](diagram/Frontent.png)

---

## ğŸ§ª Run Locally Without Docker

### ğŸ”¹ Backend (FastAPI)

```bash
cd app
python3 -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
pip install -r requirements.txt
python -m playwright install
uvicorn main:app --reload --port 8000
```

### ğŸ”¹ Frontend (Streamlit)

```bash
cd ui
streamlit run app.py
```

---

## ğŸ³ Run with Docker

```bash
docker-compose up --build
```

- Frontend: http://localhost:8501  
- Backend: http://localhost:8000  

---

## âš™ï¸ CI/CD Pipeline

```text
âœ… Defined in .github/workflows/ci.yml  
âœ… Automatically runs on every push  
âœ… Builds both frontend and backend  
âœ… Tests backend health using curl  
âœ… Gracefully fails on issues  
âœ… Uses latest Docker & GitHub runner environment  
```

---

## ğŸŒ± Future Roadmap

```text
ğŸ”¸ Integrate MongoDB Atlas for storing JSON keyword data  
ğŸ”¸ Add user authentication (JWT or OAuth)  
ğŸ”¸ Deploy on EC2, Azure, or Render  
ğŸ”¸ Add CSV/JSON export for keyword results  
ğŸ”¸ Integrate LangChain Agents for smart querying  
```

---

## ğŸ¤ Author

```text
ğŸ‘¤ Built by: Nikhil 
ğŸ“ IITian, Full Stack Data Science & GenAI Specialist  
ğŸ§‘â€ğŸ’» LinkedIn: https://linkedin.com/in/nikhildeka 
ğŸ“¬ Email: nikhiliitg07@gmail.com
```

---

## ğŸ“Œ Final Note

> â€œFrom crawling the web to meaningful insights â€” powered by LLMs, backed by Vector DBs.â€
